% Manual for FLaspm
\documentclass[a4paper]{article}
\usepackage{geometry}
\usepackage{color}
\usepackage{framed}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{cite}
\usepackage{url}
\geometry{verbose,a4paper,tmargin=2cm,bmargin=1.5cm,lmargin=2cm,rmargin=3cm}
\definecolor{shadecolor}{rgb}{0.9,0.9,0.9}
\definecolor{darkblue}{rgb}{0,0,0.5}
\setlength{\parskip}{\medskipamount}
\setlength{\parindent}{0pt}
\onehalfspacing
\hypersetup{colorlinks, urlcolor=darkblue}

\begin{document}
\SweaveOpts{engine=R}
\title{Working Paper submitted to ICES WGDEEP in 2011.\\
Not to be cited without permission from the authors.\\
FLaspm - Age Structured Production Models in FLR}
\author{Charles T T Edwards <charles.edwards@imperial.ac.uk>\\
Imperial College, London, UK\\
Finlay Scott <finlay.scott@cefas.co.uk\\
Cefas, Lowestoft, UK}
\date{January 2011}
\maketitle

\section{Introduction}

$FLaspm$ is a package for the statistical computing environment R~\cite{R}.
The package is open source and is currently hosted at GoogleCode (the source
code is freely available at \url{http://code.google.com/p/deepfishman/}).
$FLaspm$ is part of the $FLR$ project~\cite{FLRref} and requires that the
package $FLCore$ is also installed (v > 2.3).

This package implements two age structured production models (also called
stock reduction models~\cite{quinn_deriso}) based on
~\cite{Francis92} and~\cite{Walters06}, hereafter referred to as Francis and
Walters. The latter model has not yet been
properly tested and so the demonstration below focusses on the Francis model.
The package is still in development and any results generated using it
should be treated with caution.

The software can be used for projecting stock abundances forward
and also for estimating the virgin biomass of the stock. Given the flexibility
of the R environment, it is also possible to easily perform sensitivity and
risk analysis with the results.

\section{The Models}

Both models make the assumption that the initial population is at equilibrium.
A Beverton Holt model is used for the stock recruitment relationship for both
models.

\begin{equation}
R = A_{y-1} / (\alpha + \beta A_{y-1})
\end{equation}

Where A is the biomass of the mature fish. This relationship is reparameterised
in terms of virgin recruitment, $R_0$, and steepness, $h$ (the number of
recruits when the mature biomass is reduced to 20\% of its virgin level is
$h R_0$):

\begin{eqnarray}
\alpha = (4 h R_0) / (5 h -1) \\
\beta = (A_0 (1-h)) / (5h-1)
\end{eqnarray}

In the package each model is implemented twice, one version uses pure R code,
the other uses C code that is called from R.
The version that uses C code is considerably faster and
it is recommended that this version is used. The pure R version is used by
the developers to check the results (R code is much easier to debug than C).
Changing between the R and C versions is straightforward (see below).

The main difference between the models is the timing of the fishing mortality.
The Francis model assumes that fishing mortality occurs steadily throughout
the year. The Walters model assumes that the fishing mortality happens
as a 'pulse' midway through the year. This is described in more detail below.

\subsection{The Francis model}

%Main reference ~\cite{Francis92}
The Francis model assumes that the surveys are carried out at a time when it was
reasonable to assume that about half the year's fishing mortality had occurred.
Consequently, the midyear biomass is used when fitting the model.
The midyear biomass is calculated by:

\begin{equation}
B_{mid} = B_{start} e^{0.5 (F + m)}
\end{equation}

Where $B$ is the exploitable biomass, $F$ is the level of fishing in that year and $m$ is
the natural mortality. The $B_0$ that is estimated by $FLaspm$ is actually the exploitable biomass at the start of
the year. This must be taken into account when comparing the output to published
results.

The basic model equation is the standard Baranov equation:

\begin{equation}
N_{i,j} = N_{i-1,j-1} e^{F_{i-1} + m}
\end{equation}

Where $N$ is the abundance of age $j$ at the start of year $i$. $F$ is only
applied to the exploitable fish population, i.e. those at or greater than the
age of selectivity.

$F$ is calculated each year by solving the catch equation:

%biomass*(1-exp(-z))*(f/z)

\begin{equation}
C_{i} = B_{i} (1 - e^{-F_{i}-m)} F_{i} / (F_{i} + m)
\end{equation}

Where $C$ is the catch. Internally, $F$ is estimated using a simple golden search
algorithm.

\subsection{Fitting the model}

For both models $FLaspm$ uses the $fmle()$ method to estimate the
virgin exploitable biomass. The fitting is carried out in a two stage process.
First, a simulated annealing method is used. The number of iterations performed
is controlled by the control argument $maxit$ (see below for an example).
The default is 10000 iterations which may take a long time, particularly when
the pure R version is used. The second stage uses a quasi-Newton method (BFGS).
Convergence criteria for this stage can be set by the user (see the help file
for $optim$ in R for control parameters).

Before fitting is attempted, initial values are calculated (although these may
be set by the user). If multiple iterations are to be fitted, by default
initial values are only calculated for the first iteration. When the argument
$always\_eval\_initial$ is set to TRUE, initial values are calculated for each
iteration. This increases the fitting time but may improve the quality of the
fit.

\subsection{Projecting forward}

When the value of $B_0$ has been specified in the $params$ slot (either as
a result of fitting the model to data, or by setting it by hand), the
model can be projected forward using the given catch values. There are several
methods available.
The main method for projecting forward is $calc.pop.dyn()$. This returns the
explotiable biomass and mature biomass at the start of the year, the abundances
at age and the fishing mortality (or harvest rate for the Walters model).
These can also be calculated seperately using the methods $exp.biomass()$,
$mat.biomass()$, $n$ and $harvest$. Other useful methods for calculating the
midyear exploitable biomass, the log likelihood, $\hat{q}$, and indexhat are
$exp.biomass.mid()$, $calc.logl()$, $calc.qhat()$ and $indexhat$ respectively.

\subsection{Random recruitment}

It is possible to multiply the recruitment by a vector of residuals
using the $sr\_res$ slot. This can be used to simulate noisy
recruitment or to impose a trend. By default the residuals are set to 1 in each
year, i.e. the recruitment is deterministic. This is demonstrated below.

\section{Demonstration}

\subsection{Simple deterministic demonstration}
First you need to load the $FLaspm$ library

\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<quiet=TRUE,echo=TRUE,results=verbatim>>=
library(FLaspm)
@
%\end{shaded}%
\end{minipage}
\end{center}

To create an $FLaspm$ object you need to supply: the minimum and maximum ages
($amin$ and $amax$) the $catch$, the $indices$,
the natural mortality ($M$), the steepness of the SRR ($hh$), the selectivity ($sel$),
the maturity ($mat$) and the mass-at-age ($wght$)).

$amin$ and $amax$ are single numeric values. $catch$ must be an FLQuant. $index$
must be an FLQuant, or if more than one index is provided, an FLQuants object.
The year dimensions of the indices must
be the same as the catch. Any empty years should be $NA$. $M$ and $hh$ can be passed
as single numeric values (they are represented as FLQuant objects in the class).
$sel$ and $mat$ can either be single numeric values that are the age of fish entering
the fishery and the age of maturity respectively, or they can be passed as
age structured FLQuant objects that have maturity and selectivity at age.
$wght$ must be passed as an FLQuant object.

Here we will use the New Zealand Orange Roughy data set from~\cite{Francis92}.

% The keep.source argument means that comments are kept in
% results=hide, no output from R console is included
% Not sure about the quiet argument
\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<echo=TRUE,keep.source=TRUE,results=hide>>=
# Load the data - here's some I prepared earlier
data(NZOR)
catch <- NZOR[["catch"]]
index <- NZOR[["index"]]
# Check the dimensions are OK
dimnames(catch)
dimnames(index)
# Note that index has NA in some years
# Enter the parameter values
amin    <- 1
amax    <- 70
hh <- 0.95 # steepness
M <- 0.05 # natural mortality of all ages
mat_age <- 23 # age of maturity
sel_age <- 23 # age of selectivity by fishery
@
%\end{shaded}%
\end{minipage}
\end{center}


We will need to calculate the mass-at-age using the Von Bertalanffy equations
and then create an age structured FLQuant for the masses.

\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<echo=TRUE,keep.source=TRUE,results=hide>>=
# age-length parameters
Linf  <- 42.5 #cm
k     <- 0.059
t0    <- -0.346
# length-weight
alpha <- 0.0963 # grams
beta  <- 2.68
# Set up FLQuant objects for weights
# Note that we convert the mass at age to tonnes
mass_at_age <- age_to_weight(amin:amax,Linf,k,t0,alpha,beta)
w <- FLQuant(mass_at_age, dimnames=list(age=amin:amax)) / 1e6
@
%\end{shaded}%
\end{minipage}
\end{center}

Now we can create the FLaspm object by calling the $FLaspm$ constructor and
passing the data:

\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<echo=TRUE,keep.source=TRUE,results=hide>>=
or <- FLaspm(catch=catch, index=index, M=M,hh=hh,sel=sel_age,
              mat=mat_age, wght=w, amax=amax, amin=amin)
@
%\end{shaded}%
\end{minipage}
\end{center}

The final stage is to set which model we will use: Francis or Walters.
Here we will use the Francis model. As mentioned above, each model
has two versions, one that is written in pure R, the other uses C. The results
from both are the same. The C version is faster so it is better to use that:

\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<echo=TRUE,keep.source=TRUE,results=hide>>=
model(or) <- aspm.Francis.C()
@
%\end{shaded}%
\end{minipage}
\end{center}

Setting the model also sets up a function to calculate the initial values for the fitted parameters (in
this case $B_{0}$). It is possible to specify your own but unless you have a good
reason to do so (such as problems with the fit) then you should use the default
setting. To estimate the parameters use the $fmle()$ method:

\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<echo=TRUE,keep.source=TRUE,results=hide>>=
or <- fmle(or)
@
%\end{shaded}%
\end{minipage}
\end{center}

After fitting it is essential to check the quality of the fit by looking
at the likelihood profile. This can be done with the $profile()$ method. The
range argument can be used to explore the likelihood either side of the estimated
parameter value. You should see that the value of the fitted parameter occurs at the
maximum likelihood (see Figure~\ref{fig:or_profile}).


\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<echo=TRUE, fig=FALSE, keep.source=TRUE,results=hide,eval=FALSE>>=
profile(or,maxsteps=50,range=0.25)
@
%\end{shaded}%
\end{minipage}
\end{center}


\begin{figure}
\begin{center}
%\begin{shaded}%
<<echo=FALSE, fig=TRUE, results=hide>>=
profile(or,maxsteps=50,range=0.25)
@
%\end{shaded}%
\end{center}
\caption{Profile plot for the Francis model with the New Zealand Orange Roughy data}
\label{fig:or_profile}
\end{figure}

The value of the fitted parameter can be seen with the
$params()$ method:

\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<echo=TRUE,keep.source=TRUE,results=verbatim>>=
params(or)
@
%\end{shaded}%
\end{minipage}
\end{center}

Remember that $B_{0}$ is the virgin exploitable biomass at the start of the year.
Francis estimates $B_{0}$ midway through the year. We can compare our result
with Francis by calculating the midyear exploitable virgin biomass with the
$exp.biomass.mid()$ method:

\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<echo=TRUE,keep.source=TRUE,results=verbatim>>=
exp.biomass.mid(or,yrfrac = 0.5,virgin=TRUE)[,1]
@
%\end{shaded}%
\end{minipage}
\end{center}

Francis estimates the value of midyear virgin biomass as 411000
tonnes~\cite{Francis92}. So our
estimate is pretty good. We can also check out estimated value of $q_{hat}$ with
the $calc.qhat()$ method:

\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<echo=TRUE,keep.source=TRUE,results=verbatim>>=
calc.qhat(or)
@
%\end{shaded}%
\end{minipage}
\end{center}

Francis reports the estimated value of $q_{hat}$ to be 0.59~\cite{Francis92}.

%****************************************************************************
\subsection{Estimating a probability distribution for $B_{0}$}
Francis provides a Monte Carlo routine for estimating a probability
distribution for $B_{0}$. The routine answers the question: "If this were
the true $B_{0}$, how likely is it that we would get an estimate of virgin
biomass as large as or greater than $\hat{B_{0}}$", where $\hat{B_{0}}$ is
the result from the simple deterministic assessment above. Following
Francis the procedure is as follows:

\begin{enumerate}
\item Choose a trial value of $B_{0}$.
\item Calculate the biomass history for this trial $B_{0}$.
\item Generate simulated indices by assuming that the indices are normally
distributed with a mean value equal to the corresponding value in the biomass
history and with a CV of 19\% (estimated by Francis).
\item Calculate the value of $B_{0sim}$ that maximises the likelihood estimate
for the simulated survey indices.
\item Repeat steps 1-4 100 times and calculate the proportion of the $B_{0sim}$
estimates that are greater than $\hat{B_{0}}$.
\item Repeat steps 1-5 for a range of trial of $B_{0}$ values.
\end{enumerate}

This process is relatively easy to carry out using $FLaspm$ because multiple
iterations can be processed in parallel.
A sequence of $B_{0trial}$ values at
the start of the year is calculated. These are looped over using a $for$ loop.
The midyear biomass history for each
value of $B_{0}$ is calculated by setting the $params()$ value to the trial
$B_{0}$ value and using the $exp.biomass.mid()$ method.
The simulated index is generated using the R function $rnorm()$. It is possible
to generate all 100 iterations simultaneously. A new $FLaspm$ object is set up
using the simulated index and the value of $B_{0sim}$ that maximises the
likelihood for each iteration is calculated. The R code for this procedure using the New Zealand Orange Roughy
data is shown below:

\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<echo=TRUE,keep.source=TRUE,results=hide,eval=FALSE>>=
index.cv <- 0.19
niters <- 100
# Estimate the 'true' value of B0
or_true <- FLaspm(catch=catch, index=index, M=M,hh=hh,sel=sel_age,
              mat=mat_age, wght=w, fpm=1, amax=amax, amin=amin)
model(or_true) <- aspm.Francis.C()
or_true <- fmle(or_true)
B0_true <- params(or_true)['B0',]
# Set up another FLaspm object to calculate the biomass trajectory
or <- FLaspm(catch=catch, index=index, M=M,hh=hh,sel=sel_age,
              mat=mat_age, wght=w, fpm=1, amax=amax, amin=amin)
model(or) <- aspm.Francis.C()
# Set up sequence of trial B0 values
B0trial <- seq(from=300000,to=500000,length=10)
# Array to store estimated B0 values
B0store <- array(NA,dim=c(length(B0trial),niters))
for (i in 1:length(B0trial))
{
  # set the B0 value and evalutate the midyear biomass trajectory
  params(or)['B0',] <- B0trial[i]
  or.traj.mid <- exp.biomass.mid(or,yrfrac=0.5,virgin=F)
  # generate 100 random indices based on the biomass trajectory
  index.sim <- rnorm(niters,or.traj.mid,index.cv*or.traj.mid)
  # Set up an FLaspm object to fit all indices
  or.sim <- FLaspm(catch=catch, index=index.sim, M=M,hh=hh,sel=sel_age,
              mat=mat_age, wght=w, amax=amax, amin=amin)
  model(or.sim) <- aspm.Francis.C()
  # Fit all indices (takes a while...) and store the estimated value of B0
  or.sim <- fmle(or.sim)
  B0store[i,] <-(params(or.sim))
}
@
%\end{shaded}%
\end{minipage}
\end{center}

% Sneakily load in previously prepared results and other parameters
\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<echo=FALSE,results=hide>>=
index.cv <- 0.19
niters <- 100
or_true <- FLaspm(catch=catch, index=index, M=M,hh=hh,sel=sel_age,
              mat=mat_age, wght=w, fpm=1, amax=amax, amin=amin)
model(or_true) <- aspm.Francis.C()
or_true <- fmle(or_true)
B0_true <- params(or_true)['B0',]
or <- FLaspm(catch=catch, index=index, M=M,hh=hh,sel=sel_age,
              mat=mat_age, wght=w, fpm=1, amax=amax, amin=amin)
model(or) <- aspm.Francis.C()
B0trial <- seq(from=300000,to=500000,length=10)
load("B0store.RData")
@
%\end{shaded}%
\end{minipage}
\end{center}


The probability of the value of $B_{0sim}$ being greater than $B_{0trial}$
cab then be calculated and plotted. To allow comparison we plot the probability
against the midyear biomass (see Figure~\ref{fig:or_probB0_OR}).

\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<echo=TRUE, fig=FALSE, eval=TRUE>>=
propB0 <- apply(B0store>=c(B0_true),1,sum) / niters
B0trial_mid <- B0trial*exp(-0.5*M)
plot(B0trial_mid,propB0,type="l",xlab="Midyear B0", ylab="Probability")
@
%\end{shaded}%
\end{minipage}
\end{center}

\begin{figure}
\begin{center}
<<echo=FALSE, fig=TRUE, results=hide>>=
plot(B0trial_mid,propB0,type="l",xlab="Midyear B0 (t)", ylab="Probability")
@
\end{center}
\caption{Estimates of the probability that the true $B_{0mid}$ is less than
the given trial values}
\label{fig:or_probB0_OR}
\end{figure}

Although similar in shape, the probabilities are not quite the same as reported
by Francis. At the moment it is unclear what the cause of the differences
are.

To estimate the probability distribution of $B_{0}$ Francis fits a
Johnson Su distribution by maximum likelihood.
The Johnson Su distribution and likelihood function are included in the
$FLaspm$ package.
The area under the PDF curve between two value of $B_{0}$ is proportional to
the confidence that the true value of $B_{0}$ lies between these two values
(see Figure ~\ref{fig:or_pdfB0_OR}).

\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<echo=TRUE, fig=FALSE, keep.source=TRUE,results=hide>>=
initialparms <- c(g=-1,delta=1,xi=0,lambda=1)
# Scale B0trial by 1000 to help the fit
jcpars <- optim(par=initialparms,fn=Johnsonll,b=B0trial_mid/1000,m=niters,p=propB0)$par
B0midplot <- seq(from=min(B0trial_mid/1000), to = max(B0trial_mid/1000), length=100)
jp <- JohnsonPDF(jcpars,B0midplot)
plot(B0midplot,jp,type="l", xlab="Mid year B0 ('000 t)", ylab="")
@
%\end{shaded}%
\end{minipage}
\end{center}

\begin{figure}
\begin{center}
<<echo=FALSE, fig=TRUE, results=hide>>=
plot(B0midplot,jp,type="l", xlab="Midyear B0 ('000 t)", ylab="")
@
\end{center}
\caption{Estimated probability density function of $B_{0mid}$}
\label{fig:or_pdfB0_OR}
\end{figure}

Again, although similar in shape, the estimated PDF is not quite the same as reported
by Francis. The PDF estimated here is much narrower in scope.

%****************************************************************************
\subsection{Sensitivity analysis}

Sensitivity analysis can be used to evaluate the effects of uncertainty
in the model parameters. For example, Francis estimates biomass
for a range of values of natural mortality. This approach is applied here.
Using the parameter values and code that was used in the deterministic
assessment above, the only change is that natural mortality is now specified
as a vector.


\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<echo=TRUE,keep.source=TRUE,results=hide>>=
# Natural mortality is now a sequence from 0.025 to 0.1 in steps of 0.025
Msens <- seq(from=0.025, to = 0.1, by = 0.025)
or <- FLaspm(catch=catch, index=index, M=Msens,hh=hh,sel=sel_age,
              mat=mat_age, wght=w, amax=amax, amin=amin)
              model(or) <- aspm.Francis.C()
# Look at natural mortality to see that it is now 4 different values
c(or@M)
# Fit all iterations
or <- fmle(or)
@
%\end{shaded}%
\end{minipage}
\end{center}

Each value of M is treated as a seperate iteration. Consequently, there are
now four values in the $params$ slot. These can be inspected:

\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<echo=TRUE,keep.source=TRUE,results=verbatim>>=
# Use c() to split apart the iterations
c(params(or))
@
%\end{shaded}%
\end{minipage}
\end{center}

Again, we can compare our result
with Francis by calculating the midyear exploitable virgin biomass and
looking at qhat:

%calc.qhat(or) - broken for iterations

\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
%\begin{shaded}%
<<echo=TRUE,keep.source=TRUE,results=verbatim>>=
c(exp.biomass.mid(or,yrfrac = 0.5,virgin=TRUE)[,1])
c(calc.qhat(or)[[1]])
@
%\end{shaded}%
\end{minipage}
\end{center}

Francis estimates the virgin biomass for these values of M to be
452000, 411000, 372000 and 336000 respectively and for qhat to be
0.52, 0.59, 0.67 and 0.77. Again, we have good agreement with Francis.

%****************************************************************************
\subsection{Risk analysis}
Francis performs a simple risk analysis to evaluate the proposed strategy
of reducing the TAC to a target level by a desired rate. A range of rates of
reduction are tested. Risk is expressed as the probability that the fishery
would collapse within five years. A collapsed fishery is said to have
occurred if the fishing mortality >= 1 in any year.

Two sources of uncertainty are used: initial virgin biomass and uncertainty
in future recruitment.

The procedure is as follows:
\begin{enumerate}
\item An initial value of virgin biomass, $B_0$ is chosen at random from
the previously fitted Johnson Su probability distribution (see above).
\item The fishery is projected forward up to 1989 using determinsitic
recruitment and the given catches.
\item The projection continues to 1995 with catch values set as one of the
TAC schedules (with an additional 30\% increase in catch in keeping with assumed
overrun). Random recruitment is generated as a lognormal random variable where
the mean value is taken from the Beverton-Holt SRR and standard deviation of
the log of the recruitment is 1.2.
\item Steps 1 to 3 were repeated 200 times for each of the TAC schedules and
the proportion of times the fishery collapsed was calculated.
\end{enumerate}

First we set up the additional parameters and TAC schedules:

\begin{center}
\begin{minipage}[H]{0.95\textwidth}
<<echo=TRUE,keep.source=TRUE,results=hide,eval=TRUE>>=
# Set up additional parameters
iters <- 200
sigmaR <- 1.2
fcollapse <- 1
# Set up future catch schedules as an array
TAC_schedules <- array(NA,dim=c(5,6),dimnames=list(schedule=1:5,year=1990:1995))
TAC_schedules[1,] <- c(28637,25637,22637,19637,16637,13637)
TAC_schedules[2,] <- c(28637,23637,18637,13637,8637,7500)
TAC_schedules[3,] <- c(28637,21637,14637,7637,7500,7500)
TAC_schedules[4,] <- c(28637,19637,10637,7500,7500,7500)
TAC_schedules[5,] <- c(28637,16637,7500,7500,7500,7500)
prop_collapse <- rep(NA,dim(TAC_schedules)[1])
@
\end{minipage}
\end{center}

Now we loop over the TAC schedules and perform 200 simulations
for each schedule

\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
<<echo=TRUE, keep.source=TRUE,results=hide, eval=FALSE>>=
for (schedule in 1:dim(TAC_schedules)[1])
{
  # Set up new catch
  catch_proj <- window(catch,start=1978,end=1995)
  catch_proj[,ac(1990:1995)] <- TAC_schedules[schedule,] * 1.3
  # stretch index to fit catch - should add check for this in constructor
  index_proj <- window(index,start=1978,end=1995)
  # Set up random SRR residuals
  sr_res <- FLQuant(1,dimnames=dimnames(catch_proj))
  sr_res <- propagate(sr_res,iters)
  sr_res[,ac(1990:1995)] <- rlnorm(iters * (1995-1990+1),meanlog=0,sdlog=sigmaR)
  # Set up FLaspm object with the new catch and sr_res
  or <- FLaspm(catch=catch_proj, index=index_proj, M=M,hh=hh,sel=sel_age,
              mat=mat_age, wght=w, fpm=1, amax=amax, amin=amin,sr_res=sr_res)
  model(or) <- aspm.Francis.C()
  # Set up B0 values from previously fitted Johnson distribution
  # Remember we scaled B0 by 1000 for the fit
  params(or) <- propagate(params(or),iters)
  params(or)["B0",] <- rJohnson(iters,jcpars)*1000
  # Project forward
  or.proj <- calc.pop.dyn(or)
  # Who has collapsed? (F >= 1)at any time during the projection
  prop_collapse[schedule] <- length(which(apply(or.proj[["harvest"]]>=fcollapse,6,sum)>0))/iters
}
@
\end{minipage}
\end{center}

% load in previously saved results
\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
<<echo=FALSE, keep.source=FALSE,results=hide, eval=TRUE>>=
load("prop_collapse.RData")
@
\end{minipage}
\end{center}


Now we can plot the probability of collapse against the rate of TAC
reduction~\ref{fig:or_risk_OR}.
\begin{center}
\begin{minipage}[H]{0.95\textwidth}%
<<echo=TRUE, eval=FALSE, fig=FALSE>>=
plot(x=c(3000,5000,7000,9000,12000),y=prop_collapse,type="l",ylim=c(0,1),
  xlab="Rate of TAC reduction",ylab="Probability of collapse")
@
\end{minipage}
\end{center}

\begin{figure}
\begin{center}
<<echo=FALSE, eval=TRUE, fig=TRUE>>=
plot(x=c(3000,5000,7000,9000,12000),y=prop_collapse,type="l",ylim=c(0,1),
  xlab="Rate of TAC reduction",ylab="Probability of collapse")
@
\end{center}
\caption{Results of the risk analysis for New Zealand Orange Roughy}
\label{fig:or_risk_OR}
\end{figure}

The results are similar to those reported by Francis but the values are not
exactly the same. This is to be expected given the difference in the estimated
PDF of $B_0$ (see above).

%****************************************************************************

\section{Conclusion}

For the deterministic scenarios, the Francis model in $FLaspm$ estimates the
same values of virgin biomass as reported by Francis~\cite{Francis92}. However,
the behaviour of the stochastic scenarios (such as when estimating a probability
distribution for $B_0$ and the risk analysis) are slightly different. The reasons
for the differences are not yet known.

These differences mean that the results generated by the software should be treated
with caution.
Additional testing of the software is required. This is one of the key strengths
of open source software. The source code is freely available meaning that
the model is transparent. Users are
encouraged to actively participate in the development of the project by testing,
reporting bugs and suggesting solutions. This is in contrast to the 'black box'
approach, where is is not possible for users to see inside the model and the
results have to be based on trust.

Despite the differences this approach shows a great deal of promise. At the moment
two different models have been implemented and switching between them is straightforward.
Future developments of the model may include additional models. Implementing
the model in R means that all the statisical and plotting power of
R is at the users disposal. There are other advantages in using R too. For example, by
writing a script to perform an assessment it is possible to quickly rerun
the assessment with different parameter values or data. Every stage of the
assessment is recorded, increasing the transparency of the process.




%****************************************************************************



%*************************************************************************
\bibliography{flaspm_bib}{}
\bibliographystyle{plain}

\end{document}